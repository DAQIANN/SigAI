{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate some data\n",
    "\n",
    "inputs = np.random.random((100,2))\n",
    "targets = np.zeros((100,))\n",
    "targets[inputs[:,0]*1+ inputs[:,1]*1 > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [a1, a2, b] = np.random.random((3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "print(\"Beginning training: \")\n",
    "\n",
    "### Iterate through 10000 steps of gradient descent\n",
    "for i in range(100000):\n",
    "    y = inputs[:,0]\n",
    "    z = inputs[:,1]\n",
    "    \n",
    "    linear_sum = a1 * y + a2 * z + b\n",
    "    prediction = sigmoid(linear_sum)\n",
    "    \n",
    "    # (100,) dimensional array minus (100,) dimensional array\n",
    "    cost = (prediction - targets) ** 2\n",
    "    \n",
    "    dcost_dprediction = 2 * (prediction - targets)\n",
    "    dprediction_dlinear = sigmoid_derivative(prediction)\n",
    "    dlinear_a1 = y\n",
    "    dlinear_a2 = z\n",
    "    dlinear_b = np.ones((100,))\n",
    "    \n",
    "    dcost_a1 = dcost_dprediction * dprediction_dlinear * dlinear_a1\n",
    "    dcost_a2 = dcost_dprediction * dprediction_dlinear * dlinear_a2\n",
    "    dcost_b  = dcost_dprediction * dprediction_dlinear * dlinear_b\n",
    "    \n",
    "    # update parameters\n",
    "    a1 = a1 - learning_rate * np.mean(dcost_a1)\n",
    "    a2 = a2 - learning_rate * np.mean(dcost_a2)\n",
    "    b  = b  - learning_rate * np.mean(dcost_b)\n",
    "    \n",
    "    # Print loss function\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Total cost: \" + str(np.mean(cost)))\n",
    "        \n",
    "        \n",
    "print(a1, a2, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting\n",
    "Xs = inputs[targets.reshape((100,)) == 1]\n",
    "Os = inputs[targets.reshape((100,)) == 0]\n",
    "plt.scatter(Xs[:,0], Xs[:,1], marker='x', color='r')\n",
    "plt.scatter(Os[:,0], Os[:,1], marker='o', color='b')\n",
    "\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sigmoid(inputs[:,0] * a1 + inputs[:,1] * a2 + b)\n",
    "Xs = inputs[predictions > 0.5]\n",
    "Os = inputs[predictions <= 0.5]\n",
    "plt.scatter(Xs[:,0], Xs[:,1], marker='x', color='r')\n",
    "plt.scatter(Os[:,0], Os[:,1], marker='o', color='b')\n",
    "\n",
    "plt.plot()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
